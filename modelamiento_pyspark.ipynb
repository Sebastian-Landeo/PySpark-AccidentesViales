{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3234e9a1",
   "metadata": {},
   "source": [
    "<table border=\"1\" width=\"99%\">\n",
    "  <tr>\n",
    "    <td bgcolor=\"#48a259\">\n",
    "      <h1 style=\"color: #FFFFFF; text-align: center;\">Modelamiento de Accidentes Viales</h1>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a74535e-3330-4ec3-bc69-d8a1eaeb0618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ea036f-00fa-4d10-b4ad-d0ea5f711f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91a4bd09-1c34-44be-abea-29b4f69eb1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, IntegerType\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "953f26aa-d6c9-4058-9628-ee12f89bfc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "617d6224-7582-4eef-b8fd-ab087ce5d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    col, lit, when, row_number, lpad, concat, upper, trim, regexp_replace,\n",
    "    translate, ltrim, isnull, to_date, year, month, dayofmonth, date_format,\n",
    "    coalesce, to_timestamp, hour, minute, unix_timestamp, regexp_extract, split, monotonically_increasing_id, create_map\n",
    ")\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c74a8e98-88ae-44c5-9a1f-8edce623aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Accidentes Peru\") \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.6\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f399fec-b07e-41d6-beb8-e179301945b9",
   "metadata": {},
   "source": [
    "<table width=\"99%\">\n",
    "  <tr>\n",
    "    <td bgcolor=\"#FFBA39\">\n",
    "      <h2 style=\"color: #000000; text-align: left;\">Modelamiento Dimensional</h2>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a8fc18-aa91-46ed-a705-9c78e86a86fd",
   "metadata": {},
   "source": [
    "### Siniestro Viales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "903f9a94-f603-42d9-a96f-3e98f9f15d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_siniestros = spark.read.csv(\n",
    "    \"Accidentes/BBDD ONSV - SINIESTROS 2021-2023.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fa47e2a-4738-409f-8512-020ba0e2e536",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_personas = spark.read.csv(\n",
    "    \"Accidentes/BBDD ONSV - PERSONAS 2021-2023.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c687c090-3e25-4d83-9013-2a3694069273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vehiculos = spark.read.csv(\n",
    "    \"Accidentes/BBDD ONSV - VEHICULOS 2021-2023.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab536f2-e5a5-4229-9ab2-757282c540f6",
   "metadata": {},
   "source": [
    "### Dimension Ubigeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78b2c1eb-19a1-4cb9-a6e2-8ce76223e08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV de dimensi√≥n de clasificaci√≥n generado exitosamente\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Crear dimensi√≥n de clasificaci√≥n de municipalidades (solo CSV de referencia) ---\n",
    "clasificacion_map = {\n",
    "    \"A\": \"Municipalidades provinciales pertenecientes a ciudades principales\",\n",
    "    \"B\": \"Municipalidades provinciales NO pertenecientes a ciudades principales\",\n",
    "    \"C\": \"Municipalidades distritales de Lima Metropolitana\",\n",
    "    \"D\": \"Municipalidades distritales pertenecientes a otras ciudades principales\",\n",
    "    \"E\": \"Municipalidades distritales NO pertenecientes a ciudades principales, con m√°s de 70% de poblaci√≥n urbana\",\n",
    "    \"F\": \"Municipalidades distritales NO pertenecientes a ciudades principales, con poblaci√≥n urbana entre 35% y 70%\",\n",
    "    \"G\": \"Municipalidades distritales NO pertenecientes a ciudades principales, con menos de 35% de poblaci√≥n urbana\"\n",
    "}\n",
    "\n",
    "# Guardar CSV de dimensi√≥n de clasificaci√≥n\n",
    "dim_clas_muni = pd.DataFrame([\n",
    "    {\"clasificacion_municipalidad\": k, \"clasificacion_muni_desc\": v}\n",
    "    for k, v in clasificacion_map.items()\n",
    "])\n",
    "dim_clas_muni.to_csv(\n",
    "    \"Dimensiones/dim_clasificacion_muni.csv\",\n",
    "    index=False,\n",
    "    quoting=csv.QUOTE_ALL,\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "print(\"CSV de dimensi√≥n de clasificaci√≥n generado exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb6fa5af-7b42-4715-b53d-c22b1916a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Leer RENAMU ---\n",
    "renamu_df = spark.read.csv(\n",
    "    \"Renamu/Base_RENAMU_2022_f.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\";\"\n",
    ")\n",
    "\n",
    "# Seleccionar columnas principales\n",
    "dim_ubigeo = renamu_df.select(\n",
    "    lpad(col(\"Ubigeo\").cast(\"string\"), 6, \"0\").alias(\"ubigeo\"),\n",
    "    col(\"Departamento\").alias(\"departamento\"),\n",
    "    col(\"ccdd\").alias(\"codigo_departamento\"),    \n",
    "    col(\"Provincia\").alias(\"provincia\"),\n",
    "    col(\"ccpp\").alias(\"codigo_provincia\"),\n",
    "    col(\"Distrito\").alias(\"distrito\"),\n",
    "    col(\"ccdi\").alias(\"codigo_distrito\"),\n",
    "    col(\"TIPOMUNI\").cast(\"int\").alias(\"tipomuni\")\n",
    ")\n",
    "\n",
    "# --- 3. Leer regi√≥n natural desde Excel ---\n",
    "excel_df = pd.read_excel(\"Ubigeo/UBIGEO 2022_1891 distritos.xlsx\", dtype=str)\n",
    "excel_df = excel_df.rename(columns={\"IDDIST\": \"ubigeo\", \"REGION NATURAL\": \"region_natural\"})\n",
    "excel_df[\"ubigeo\"] = excel_df[\"ubigeo\"].str.zfill(6)\n",
    "region_df = spark.createDataFrame(excel_df[[\"ubigeo\", \"region_natural\"]])\n",
    "\n",
    "# --- 4. Leer clasificaci√≥n municipalidad A-G ---\n",
    "clasif_df = spark.read.csv(\n",
    "    \"Ubigeo/clasificacion_municipalidades_abcg.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\",\"\n",
    ").withColumn(\"ubigeo\", lpad(col(\"ubigeo\").cast(\"string\"), 6, \"0\")) \\\n",
    " .withColumnRenamed(\"clasificacion_muni\", \"clasificacion_municipalidad\")\n",
    "\n",
    "# --- 5. Unir UBIGEO con regi√≥n y clasificaci√≥n ---\n",
    "dim_ubigeo = dim_ubigeo \\\n",
    "    .join(region_df, on=\"ubigeo\", how=\"left\") \\\n",
    "    .join(clasif_df, on=\"ubigeo\", how=\"left\")\n",
    "\n",
    "# --- 6. Descripci√≥n de TIPOMUNI ---\n",
    "dim_ubigeo = dim_ubigeo.withColumn(\n",
    "    \"tipo_muni_desc\",\n",
    "    when(col(\"tipomuni\") == 1, \"Municipalidad Provincial\")\n",
    "    .when(col(\"tipomuni\") == 2, \"Municipalidad Distrital\")\n",
    "    .when(col(\"tipomuni\") == 3, \"Municipalidad de Centro Poblado\")\n",
    "    .otherwise(\"No especificado\")\n",
    ")\n",
    "\n",
    "# --- 7. ID autoincremental ---\n",
    "window = Window.orderBy(\"ubigeo\")\n",
    "dim_ubigeo = dim_ubigeo.withColumn(\"id_ubigeo\", row_number().over(window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c15681c1-a17d-4252-a8e9-428f391fa053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Cargar poblaci√≥n 2022 ---\n",
    "df_pob = pd.read_excel(\n",
    "    \"./Ubigeo/Proyecciones_poblacion_2018_2022.xlsx\",\n",
    "    skiprows=1,\n",
    "    dtype={'UBIGEO': str}\n",
    ")\n",
    "df_pob.columns = df_pob.columns.str.strip()\n",
    "df_pob[\"UBIGEO\"] = df_pob[\"UBIGEO\"].fillna(\"\").str.strip().str.zfill(6)\n",
    "df_pob = df_pob[df_pob[\"UBIGEO\"].str.match(r\"^\\d{6}$\", na=False)]\n",
    "df_pob_2022 = df_pob[[\"UBIGEO\", \"2022\"]].rename(columns={\"2022\": \"habitantes\"})\n",
    "df_pob_2022[\"habitantes\"] = pd.to_numeric(df_pob_2022[\"habitantes\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "poblacion_spark = spark.createDataFrame(df_pob_2022).withColumnRenamed(\"UBIGEO\", \"ubigeo\")\n",
    "\n",
    "# --- 9. Unir poblaci√≥n ---\n",
    "dim_ubigeo = dim_ubigeo.join(poblacion_spark, on=\"ubigeo\", how=\"left\")\n",
    "\n",
    "# --- 10. Reordenar columnas final ---\n",
    "cols = dim_ubigeo.columns\n",
    "ordered_cols = [\"id_ubigeo\", \"ubigeo\"] + [c for c in cols if c not in (\"id_ubigeo\", \"ubigeo\")]\n",
    "dim_ubigeo = dim_ubigeo.select(ordered_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64d1a3f0-e6a4-4cf2-aaf8-849e21f79b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV de dimensi√≥n UBIGEO generado exitosamente\n"
     ]
    }
   ],
   "source": [
    "# --- 11. Convertir a Pandas y guardar CSV ---\n",
    "df_pd = dim_ubigeo.toPandas()\n",
    "df_pd[\"ubigeo\"] = df_pd[\"ubigeo\"].astype(str).str.zfill(6)\n",
    "df_pd.to_csv(\"Dimensiones/dim_ubigeo.csv\", index=False)\n",
    "\n",
    "print(\"CSV de dimensi√≥n UBIGEO generado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5483e6c0-58ae-4438-9a26-2a31362736c1",
   "metadata": {},
   "source": [
    "### Dimension Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61fcbb3f-0fdc-4ee2-8612-0ae1a033f97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total registros en dim_tiempo: 6548\n"
     ]
    }
   ],
   "source": [
    "df_tiempo = df_siniestros \\\n",
    "    .withColumn(\"fecha\", to_date(col(\"FECHA SINIESTRO\"), \"dd/MM/yyyy\")) \\\n",
    "    .withColumn(\"hora_raw\", trim(col(\"HORA SINIESTRO\"))) \\\n",
    "    .withColumn(\"hora_only\", regexp_extract(col(\"hora_raw\"), \"([0-9]{1,2}:[0-9]{2}(?::[0-9]{2})?)\", 1)) \\\n",
    "    .withColumn(\"hora_norm\",\n",
    "        when(col(\"hora_only\") != \"\", col(\"hora_only\")).otherwise(col(\"hora_raw\"))\n",
    "    ) \\\n",
    "    .withColumn(\"hora_norm\",\n",
    "        when(col(\"hora_norm\").rlike(\"^[0-9]{1,2}:[0-9]{2}$\"),\n",
    "             concat(\n",
    "                 lpad(split(col(\"hora_norm\"), \":\").getItem(0), 2, \"0\"),\n",
    "                 lit(\":\"),\n",
    "                 split(col(\"hora_norm\"), \":\").getItem(1),\n",
    "                 lit(\":00\")\n",
    "             )\n",
    "        ).otherwise(col(\"hora_norm\"))\n",
    "    ) \\\n",
    "    .withColumn(\"timestamp_completo\",\n",
    "        to_timestamp(concat(date_format(col(\"fecha\"), \"yyyy-MM-dd\"), lit(\" \"), col(\"hora_norm\")),\n",
    "                     \"yyyy-MM-dd HH:mm:ss\")\n",
    "    ) \\\n",
    "    .withColumn(\"hora_num\", hour(col(\"timestamp_completo\"))) \\\n",
    "    .withColumn(\"minuto_num\", minute(col(\"timestamp_completo\"))) \\\n",
    "    .withColumn(\"fecha_hora_unix\", unix_timestamp(col(\"timestamp_completo\"))) \\\n",
    "    .withColumn(\"anio\", year(col(\"fecha\"))) \\\n",
    "    .withColumn(\"mes\", month(col(\"fecha\"))) \\\n",
    "    .withColumn(\"dia\", dayofmonth(col(\"fecha\"))) \\\n",
    "    .withColumn(\"dia_semana\", date_format(col(\"fecha\"), \"EEEE\")) \\\n",
    "    .withColumn(\"mes_str\", lpad(col(\"mes\").cast(\"string\"), 2, \"0\")) \\\n",
    "    .withColumn(\"pk_tiempo\",\n",
    "        when(col(\"timestamp_completo\").isNotNull(),\n",
    "             date_format(col(\"timestamp_completo\"), \"yyyyMMddHHmmss\")\n",
    "        ).otherwise(\n",
    "             concat(\n",
    "                 col(\"anio\").cast(\"string\"),\n",
    "                 col(\"mes_str\"),\n",
    "                 lpad(col(\"dia\").cast(\"string\"), 2, \"0\"),\n",
    "                 lit(\"000000\")\n",
    "             )\n",
    "        )\n",
    "    ) \\\n",
    "    .withColumn(\"trimestre\",\n",
    "        when(col(\"mes\").between(1,3), 1)\n",
    "        .when(col(\"mes\").between(4,6), 2)\n",
    "        .when(col(\"mes\").between(7,9), 3)\n",
    "        .otherwise(4)\n",
    "    ) \\\n",
    "    .withColumn(\"semestre\", when(col(\"mes\") <= 6, 1).otherwise(2)) \\\n",
    "    .withColumn(\"nombre_mes\", date_format(col(\"fecha\"), \"MMMM\"))\n",
    "\n",
    "dim_tiempo = df_tiempo.select(\n",
    "    \"pk_tiempo\",\n",
    "    \"fecha\",\n",
    "    \"anio\",\n",
    "    \"mes\",\n",
    "    \"dia\",\n",
    "    \"dia_semana\",\n",
    "    \"fecha_hora_unix\",\n",
    "    \"mes_str\",\n",
    "    \"trimestre\",\n",
    "    \"semestre\",\n",
    "    \"nombre_mes\"\n",
    ").distinct().orderBy(\"fecha\", \"fecha_hora_unix\")\n",
    "\n",
    "print(f\"\\nTotal registros en dim_tiempo: {dim_tiempo.count()}\")\n",
    "\n",
    "dim_tiempo_pd = dim_tiempo.toPandas()\n",
    "dim_tiempo_pd.to_csv(\"Dimensiones/dim_tiempo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2436ae4a-e797-4a3b-9863-80d38ab162ec",
   "metadata": {},
   "source": [
    "### Dim Red Vial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2edf6e6-715c-4d02-a8e1-acb03b38b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0 Leer CSV DIRECTAMENTE \n",
    "\n",
    "df_red_vial = spark.read.csv(\n",
    "    \"Red_Vial/RedVial_2024_clean.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\",\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 1. Selecci√≥n de columnas √∫tiles\n",
    "# ================================\n",
    "dim_red_vial = df_red_vial.select(\n",
    "    F.col(\"Id\").alias(\"cod_red_vial\"),\n",
    "    F.col(\"cCodRuta\").alias(\"codigo_ruta\"),\n",
    "    F.col(\"cNomRuta\").alias(\"nombre_ruta\"),\n",
    "    F.col(\"cIdTramo\").alias(\"id_tramo\"),\n",
    "    F.col(\"dkmInicio\").alias(\"km_inicio\"),\n",
    "    F.col(\"dkmFinal\").alias(\"km_final\"),\n",
    "    F.col(\"dLongitud\").alias(\"longitud_km\"),\n",
    "    F.col(\"dNroCarril\").alias(\"nro_carriles\"),\n",
    "    F.col(\"dAncCalzad\").alias(\"ancho_calzada\"),\n",
    "    F.col(\"cTipRed\").alias(\"tipo_red_raw\"),\n",
    "    F.col(\"cClasifica\").alias(\"clasificacion_raw\"),\n",
    "    F.col(\"cAutopista\").alias(\"es_autopista_raw\"),\n",
    "    F.col(\"cSentido\").alias(\"sentido_raw\"),\n",
    "    F.col(\"cCodDepart\").alias(\"cod_departamento\"),\n",
    "    F.col(\"cDepartame\").alias(\"departamento\"),\n",
    "    F.col(\"cCodProvin\").alias(\"cod_provincia\"),\n",
    "    F.col(\"cRegion\").alias(\"region\"),\n",
    "    F.col(\"cTopografi\").alias(\"topografia_raw\"),\n",
    "    F.col(\"cEstado\").alias(\"estado_via_raw\"),\n",
    "    F.col(\"dSuperfici\").alias(\"superficie_km2\"),\n",
    "    F.col(\"dLogistico\").alias(\"logistico\"),\n",
    "    F.col(\"cOperacion\").alias(\"operacion\"),\n",
    "    F.col(\"dIMD\").alias(\"imd\"),\n",
    "    F.col(\"cPeajes\").alias(\"peajes\")\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 2. Normalizaciones\n",
    "# ================================\n",
    "# Tipo de red\n",
    "dim_red_vial = dim_red_vial.withColumn(\n",
    "    \"tipo_red\",\n",
    "    F.when(F.lower(\"tipo_red_raw\") == \"rn\", \"Red Nacional\")\n",
    "     .when(F.lower(\"tipo_red_raw\") == \"rv\", \"Red Vial\")\n",
    "     .otherwise(\"Otro\")\n",
    ")\n",
    "\n",
    "# Clasificaci√≥n\n",
    "dim_red_vial = dim_red_vial.withColumn(\n",
    "    \"clasificacion\",\n",
    "    F.when(F.lower(\"clasificacion_raw\").like(\"%nacional%\"), \"Nacional\")\n",
    "     .when(F.lower(\"clasificacion_raw\").like(\"%ramal%\"), \"Ramal\")\n",
    "     .when(F.lower(\"clasificacion_raw\").like(\"%transversal%\"), \"Transversal\")\n",
    "     .otherwise(\"Otro\")\n",
    ")\n",
    "\n",
    "# Autopista\n",
    "dim_red_vial = dim_red_vial.withColumn(\n",
    "    \"es_autopista\",\n",
    "    F.when(F.col(\"es_autopista_raw\").isin([\"1\", 1, \"Si\", \"SI\"]), \"Si\")\n",
    "     .otherwise(\"No\")\n",
    ")\n",
    "\n",
    "# Sentido\n",
    "dim_red_vial = dim_red_vial.withColumn(\n",
    "    \"sentido\",\n",
    "    F.when(F.lower(\"sentido_raw\") == \"uc\", \"Unidireccional\")\n",
    "     .when(F.lower(\"sentido_raw\") == \"db\", \"Bidireccional\")\n",
    "     .otherwise(\"Desconocido\")\n",
    ")\n",
    "\n",
    "# Topograf√≠a\n",
    "dim_red_vial = dim_red_vial.withColumn(\n",
    "    \"topografia\",\n",
    "    F.when(F.lower(\"topografia_raw\") == \"sierra\", \"Sierra\")\n",
    "     .when(F.lower(\"topografia_raw\") == \"costa\", \"Costa\")\n",
    "     .when(F.lower(\"topografia_raw\") == \"selva\", \"Selva\")\n",
    "     .otherwise(\"Otro\")\n",
    ")\n",
    "\n",
    "# Estado de la v√≠a\n",
    "dim_red_vial = dim_red_vial.withColumn(\n",
    "    \"estado_via\",\n",
    "    F.when(F.lower(\"estado_via_raw\") == \"monta√±oso\", \"Monta√±oso\")\n",
    "     .when(F.lower(\"estado_via_raw\") == \"plano\", \"Plano\")\n",
    "     .otherwise(\"Otro\")\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 3. ID Autogenerado\n",
    "# ================================\n",
    "window = Window.orderBy(F.monotonically_increasing_id())\n",
    "dim_red_vial = dim_red_vial.withColumn(\n",
    "    \"id_red_vial\",\n",
    "    F.row_number().over(window)\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 4. Selecci√≥n final limpia\n",
    "# ================================\n",
    "dim_red_vial = dim_red_vial.select(\n",
    "    \"id_red_vial\",\n",
    "    \"cod_red_vial\",\n",
    "    \"codigo_ruta\",\n",
    "    \"nombre_ruta\",\n",
    "    \"id_tramo\",\n",
    "    \"km_inicio\",\n",
    "    \"km_final\",\n",
    "    \"longitud_km\",\n",
    "    \"nro_carriles\",\n",
    "    \"ancho_calzada\",\n",
    "    \"tipo_red\",\n",
    "    \"clasificacion\",\n",
    "    \"es_autopista\",\n",
    "    \"sentido\",\n",
    "    \"cod_departamento\",\n",
    "    \"departamento\",\n",
    "    \"cod_provincia\",\n",
    "    \"region\",\n",
    "    \"topografia\",\n",
    "    \"estado_via\",\n",
    "    \"superficie_km2\",\n",
    "    \"logistico\",\n",
    "    \"operacion\",\n",
    "    \"imd\",\n",
    "    \"peajes\"\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 5. Guardado\n",
    "# ================================\n",
    "dim_red_vial.toPandas().to_csv(\n",
    "    \"Dimensiones/dim_red_vial.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64297faa-4082-4d37-ba90-a09323aa620a",
   "metadata": {},
   "source": [
    "### Dimension Personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ef15f3c-e210-42d8-9a39-3adb0d075706",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================================\n",
    "# 2. Selecci√≥n de columnas de dimensi√≥n\n",
    "# ================================\n",
    "\n",
    "dim_personas = df_personas.select(\n",
    "    F.col(\"C√ìDIGO SINIESTRO\").alias(\"cod_siniestro\"),\n",
    "    F.col(\"C√ìDIGO PERSONA\").alias(\"cod_persona\"),\n",
    "    F.col(\"SEXO\").alias(\"sexo_raw\"),\n",
    "    F.col(\"EDAD\").cast(\"int\").alias(\"edad\"),\n",
    "    F.col(\"TIPO PERSONA\").alias(\"tipo_persona_raw\"),\n",
    "    F.col(\"GRAVEDAD\").alias(\"gravedad_raw\"),\n",
    "    F.col(\"SITUACI√ìN DE PERSONA\").alias(\"situacion_persona_raw\"),\n",
    "    F.col(\"PA√çS DE NACIONALIDAD\").alias(\"nacionalidad\"),\n",
    "    F.col(\"OTRO PA√çS DE NACIONALIDAD\").alias(\"nacionalidad_otro\"),\n",
    "    F.col(\"POSEE LICENCIA\").alias(\"posee_licencia_raw\"),\n",
    "    F.col(\"ESTADO LICENCIA\").alias(\"estado_licencia\"),\n",
    "    F.col(\"CLASE_LICENCIA\").alias(\"clase_licencia\"),\n",
    "    F.col(\"¬øSE SOMETI√ì A DOSAJE ET√çLICO CUALITATIVO?\").alias(\"dosaje_cualit_raw\"),\n",
    "    F.col(\"RESULTADO DEL DOSAJE ET√çLICO CUALITATIVO\").alias(\"dosaje_cualit_res\"),\n",
    "    F.col(\"¬øSE SOMETI√ì A DOSAJE ET√çLICO CUANTITATIVO?\").alias(\"dosaje_cuantit_raw\")\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 3. Normalizaci√≥n\n",
    "# ================================\n",
    "\n",
    "# Sexo\n",
    "dim_personas = dim_personas.withColumn(\n",
    "    \"sexo\",\n",
    "    F.when(F.lower(\"sexo_raw\").like(\"%masc%\"), \"M\")\n",
    "     .when(F.lower(\"sexo_raw\").like(\"%fem%\"), \"F\")\n",
    "     .otherwise(\"O\")\n",
    ")\n",
    "\n",
    "# Tipo persona\n",
    "dim_personas = dim_personas.withColumn(\n",
    "    \"tipo_persona\",\n",
    "    F.when(F.lower(\"tipo_persona_raw\").like(\"%conductor%\"), \"Conductor\")\n",
    "     .when(F.lower(\"tipo_persona_raw\").like(\"%pasaj%\"), \"Pasajero\")\n",
    "     .when(F.lower(\"tipo_persona_raw\").like(\"%peat%\"), \"Peat√≥n\")\n",
    "     .otherwise(\"Otro\")\n",
    ")\n",
    "\n",
    "# Gravedad\n",
    "dim_personas = dim_personas.withColumn(\n",
    "    \"gravedad\",\n",
    "    F.when(F.lower(\"gravedad_raw\").like(\"%falle%\"), \"Fallecido\")\n",
    "     .when(F.lower(\"gravedad_raw\").like(\"%lesion%\"), \"Herido\")\n",
    "     .otherwise(\"Ileso\")\n",
    ")\n",
    "\n",
    "# Situaci√≥n\n",
    "dim_personas = dim_personas.withColumn(\n",
    "    \"situacion_persona\",\n",
    "    F.when(F.lower(\"situacion_persona_raw\").like(\"%ident%\"), \"Identificado\")\n",
    "     .otherwise(\"No identificado\")\n",
    ")\n",
    "\n",
    "# Posee licencia\n",
    "dim_personas = dim_personas.withColumn(\n",
    "    \"tiene_licencia\",\n",
    "    F.when(F.lower(\"posee_licencia_raw\") == \"si\", \"Si\")\n",
    "     .when(F.lower(\"posee_licencia_raw\") == \"no\", \"No\")\n",
    "     .otherwise(\"Desconocido\")\n",
    ")\n",
    "\n",
    "# Dosaje cualitativo\n",
    "dim_personas = dim_personas.withColumn(\n",
    "    \"dosaje_cualit\",\n",
    "    F.when(F.lower(\"dosaje_cualit_raw\") == \"si\", \"Si\")\n",
    "     .when(F.lower(\"dosaje_cualit_raw\") == \"no\", \"No\")\n",
    "     .otherwise(\"Desconocido\")\n",
    ")\n",
    "\n",
    "# Dosaje cuantitativo\n",
    "dim_personas = dim_personas.withColumn(\n",
    "    \"dosaje_cuantit\",\n",
    "    F.when(F.lower(\"dosaje_cuantit_raw\") == \"si\", \"Si\")\n",
    "     .when(F.lower(\"dosaje_cuantit_raw\") == \"no\", \"No\")\n",
    "     .otherwise(\"Desconocido\")\n",
    ")\n",
    "\n",
    "# Grupo de edad\n",
    "dim_personas = dim_personas.withColumn(\n",
    "    \"grupo_edad\",\n",
    "    F.when(F.col(\"edad\") < 12, \"Ni√±o\")\n",
    "     .when((F.col(\"edad\") >= 12) & (F.col(\"edad\") <= 17), \"Adolescente\")\n",
    "     .when((F.col(\"edad\") >= 18) & (F.col(\"edad\") <= 59), \"Adulto\")\n",
    "     .when(F.col(\"edad\") >= 60, \"Adulto mayor\")\n",
    "     .otherwise(\"No especificado\")\n",
    ")\n",
    "\n",
    "dim_personas = dim_personas.withColumn(\"edad\", F.col(\"edad\").cast(\"int\"))\n",
    "\n",
    "# ================================\n",
    "# 4. ID Autogenerado\n",
    "# ================================\n",
    "\n",
    "window = Window.orderBy(F.monotonically_increasing_id())\n",
    "\n",
    "dim_personas = dim_personas.withColumn(\n",
    "    \"id_persona\",\n",
    "    F.row_number().over(window)\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 5. Selecci√≥n final\n",
    "# ================================\n",
    "\n",
    "dim_personas = dim_personas.select(\n",
    "    \"id_persona\",\n",
    "    \"cod_siniestro\",  # ‚Üê CLAVE: Ahora est√° incluido\n",
    "    \"cod_persona\",\n",
    "    \"sexo\",\n",
    "    \"edad\",\n",
    "    \"grupo_edad\",\n",
    "    \"tipo_persona\",\n",
    "    \"gravedad\",\n",
    "    \"situacion_persona\",\n",
    "    \"nacionalidad\",\n",
    "    \"nacionalidad_otro\",\n",
    "    \"tiene_licencia\",\n",
    "    \"estado_licencia\",\n",
    "    \"clase_licencia\",\n",
    "    \"dosaje_cualit\",\n",
    "    \"dosaje_cualit_res\",\n",
    "    \"dosaje_cuantit\"\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 6. Guardar resultado\n",
    "# ================================\n",
    "pdf = dim_personas.toPandas()\n",
    "pdf[\"edad\"] = pdf[\"edad\"].astype(\"Int64\")  # entero con null permitido\n",
    "pdf.to_csv(\"Dimensiones/dim_personas.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045fa5b7-f947-4c33-b972-28d49331d102",
   "metadata": {},
   "source": [
    "### Dimension Vehiculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15f74615-b798-4c1d-8c1b-4925b4cd6057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 2. Selecci√≥n de columnas √∫tiles\n",
    "# ================================\n",
    "dim_vehiculo = df_vehiculos.select(\n",
    "    F.col(\"C√ìDIGO SINIESTRO\").alias(\"cod_siniestro\"),\n",
    "    F.col(\"C√ìDIGO VEHICULO\").alias(\"cod_vehiculo\"),\n",
    "    F.col(\"SITUACI√ìN VEH√çCULO\").alias(\"situacion_raw\"),\n",
    "    F.col(\"ESTADO MODALIDAD\").alias(\"estado_modalidad\"),\n",
    "    F.col(\"MODALIDAD DE TRANSPORTE\").alias(\"modalidad_raw\"),\n",
    "    F.col(\"ELEMENTO TRANSPORTADO\").alias(\"elemento_transportado\"),\n",
    "    F.col(\"AMBITO SERVICIO\").alias(\"ambito_servicio\"),\n",
    "    F.col(\"POSEE SEGURO\").alias(\"posee_seguro_raw\"),\n",
    "    F.col(\"ESTADO SOAT\").alias(\"estado_soat\"),\n",
    "    F.col(\"TIPO SEGURO\").alias(\"tipo_seguro\"),\n",
    "    F.col(\"COMPA√ëIA SEGURO\").alias(\"compania_seguro\"),\n",
    "    F.col(\"POSEE CITV\").alias(\"posee_citv_raw\"),\n",
    "    F.col(\"ESTADO CITV\").alias(\"estado_citv\"),\n",
    "    F.col(\"LUGAR IMPACTO VEH√çCULO\").alias(\"lugar_impacto\"),\n",
    "    F.col(\"VEH√çCULO\").alias(\"tipo_vehiculo_raw\"),\n",
    "    F.col(\"TIPO SINIESTRO\").alias(\"tipo_siniestro_raw\"),\n",
    "    F.col(\"TIPO DE V√çA\").alias(\"tipo_via_raw\")\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 3. Normalizaciones\n",
    "# ================================\n",
    "\n",
    "# Situaci√≥n del veh√≠culo\n",
    "dim_vehiculo = dim_vehiculo.withColumn(\n",
    "    \"situacion\",\n",
    "    F.when(F.lower(\"situacion_raw\").like(\"%ident%\"), \"Identificado\")\n",
    "     .otherwise(\"No identificado\")\n",
    ")\n",
    "\n",
    "# Modalidad\n",
    "dim_vehiculo = dim_vehiculo.withColumn(\n",
    "    \"modalidad\",\n",
    "    F.when(F.lower(\"modalidad_raw\").like(\"%particular%\"), \"Particular\")\n",
    "     .when(F.lower(\"modalidad_raw\").like(\"%carga%\"), \"Carga\")\n",
    "     .when(F.lower(\"modalidad_raw\").like(\"%pasaj%\"), \"Pasajeros\")\n",
    "     .otherwise(\"Otro\")\n",
    ")\n",
    "\n",
    "# Posee seguro\n",
    "dim_vehiculo = dim_vehiculo.withColumn(\n",
    "    \"posee_seguro\",\n",
    "    F.when(F.lower(\"posee_seguro_raw\") == \"si\", \"Si\")\n",
    "     .when(F.lower(\"posee_seguro_raw\") == \"no\", \"No\")\n",
    "     .otherwise(\"Desconocido\")\n",
    ")\n",
    "\n",
    "# CITV\n",
    "dim_vehiculo = dim_vehiculo.withColumn(\n",
    "    \"posee_citv\",\n",
    "    F.when(F.lower(\"posee_citv_raw\") == \"si\", \"Si\")\n",
    "     .when(F.lower(\"posee_citv_raw\") == \"no\", \"No\")\n",
    "     .otherwise(\"Desconocido\")\n",
    ")\n",
    "\n",
    "# Tipo de veh√≠culo\n",
    "dim_vehiculo = dim_vehiculo.withColumn(\n",
    "    \"tipo_vehiculo\",\n",
    "    F.when(F.lower(\"tipo_vehiculo_raw\").like(\"%moto%\"), \"Motocicleta\")\n",
    "     .when(F.lower(\"tipo_vehiculo_raw\").like(\"%camion%\"), \"Cami√≥n\")\n",
    "     .when(F.lower(\"tipo_vehiculo_raw\").like(\"%auto%\"), \"Autom√≥vil\")\n",
    "     .when(F.lower(\"tipo_vehiculo_raw\").like(\"%pickup%\"), \"Pickup\")\n",
    "     .otherwise(\"Otro\")\n",
    ")\n",
    "\n",
    "# Normalizaci√≥n tipo de v√≠a\n",
    "dim_vehiculo = dim_vehiculo.withColumn(\n",
    "    \"tipo_via\",\n",
    "    F.when(F.lower(\"tipo_via_raw\").like(\"%carretera%\"), \"Carretera\")\n",
    "     .when(F.lower(\"tipo_via_raw\").like(\"%avenida%\"), \"Avenida\")\n",
    "     .when(F.lower(\"tipo_via_raw\").like(\"%calle%\"), \"Calle\")\n",
    "     .otherwise(\"Otro\")\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 4. ID Autogenerado\n",
    "# ================================\n",
    "window = Window.orderBy(F.monotonically_increasing_id())\n",
    "\n",
    "dim_vehiculo = dim_vehiculo.withColumn(\n",
    "    \"id_vehiculo\",\n",
    "    F.row_number().over(window)\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 5. Selecci√≥n final limpia\n",
    "# ================================\n",
    "dim_vehiculo = dim_vehiculo.select(\n",
    "    \"id_vehiculo\",\n",
    "    \"cod_vehiculo\",\n",
    "    \"cod_siniestro\",\n",
    "    \"situacion\",\n",
    "    \"estado_modalidad\",\n",
    "    \"modalidad\",\n",
    "    \"elemento_transportado\",\n",
    "    \"ambito_servicio\",\n",
    "    \"posee_seguro\",\n",
    "    \"estado_soat\",\n",
    "    \"tipo_seguro\",\n",
    "    \"compania_seguro\",\n",
    "    \"posee_citv\",\n",
    "    \"estado_citv\",\n",
    "    \"lugar_impacto\",\n",
    "    \"tipo_vehiculo\",\n",
    "    \"tipo_via\"\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 6. Guardado final\n",
    "# ================================\n",
    "dim_vehiculo.toPandas().to_csv(\n",
    "    \"Dimensiones/dim_vehiculo.csv\",\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460766fe-fc3f-44a7-96c0-4984e71dedd0",
   "metadata": {},
   "source": [
    "### Dimension tipo Siniestro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7504e8e0-9a91-42c1-b59c-994518daa5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 1. Selecci√≥n de columnas fuente\n",
    "# ================================\n",
    "dim_tipo_siniestro = df_siniestros.select(\n",
    "    F.col(\"CLASE SINIESTRO\").alias(\"clase_siniestro_raw\")\n",
    ").dropDuplicates()\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 2. Normalizaci√≥n de CLASE DE SINIESTRO\n",
    "# ================================\n",
    "dim_tipo_siniestro = dim_tipo_siniestro.withColumn(\n",
    "    \"clase_siniestro\",\n",
    "    F.when(F.lower(\"clase_siniestro_raw\").like(\"%despis%\"), \"Despiste\")\n",
    "     .when(F.lower(\"clase_siniestro_raw\").like(\"%atrop%\") & F.lower(\"clase_siniestro_raw\").like(\"%fuga%\"), \"Atropello (Fuga)\")\n",
    "     .when(F.lower(\"clase_siniestro_raw\").like(\"%atrop%\"), \"Atropello\")\n",
    "     .when(F.lower(\"clase_siniestro_raw\").like(\"%choque%\") & F.lower(\"clase_siniestro_raw\").like(\"%fuga%\"), \"Choque (Fuga)\")\n",
    "     .when(F.lower(\"clase_siniestro_raw\").like(\"%choque%\") & F.lower(\"clase_siniestro_raw\").like(\"%objeto%\"), \"Choque con objeto fijo\")\n",
    "     .when(F.lower(\"clase_siniestro_raw\").like(\"%choque%\"), \"Choque\")\n",
    "     .when(F.lower(\"clase_siniestro_raw\").like(\"%caida%\"), \"Ca√≠da de pasajero\")\n",
    "     .when(F.lower(\"clase_siniestro_raw\").like(\"%volc%\"), \"Volcadura\")\n",
    "     .when(F.lower(\"clase_siniestro_raw\").like(\"%ferro%\"), \"Ferroviario\")\n",
    "     .when(F.lower(\"clase_siniestro_raw\").like(\"%incend%\"), \"Incendio\")\n",
    "     .when(F.lower(\"clase_siniestro_raw\").like(\"%especial%\"), \"Especial\")\n",
    "     .otherwise(F.initcap(\"clase_siniestro_raw\"))\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 3. ID Autogenerado\n",
    "# ================================\n",
    "window = Window.orderBy(F.monotonically_increasing_id())\n",
    "\n",
    "dim_tipo_siniestro = dim_tipo_siniestro.withColumn(\n",
    "    \"id_tipo_siniestro\",\n",
    "    F.row_number().over(window)\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 4. Selecci√≥n final\n",
    "# ================================\n",
    "dim_tipo_siniestro = dim_tipo_siniestro.select(\n",
    "    \"id_tipo_siniestro\",\n",
    "    \"clase_siniestro\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e4867be-984f-48fb-940f-5a2855d8e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 5. Guardado final\n",
    "# ================================\n",
    "dim_tipo_siniestro.toPandas().to_csv(\n",
    "    \"Dimensiones/dim_tipo_siniestro.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7129a9ac-f665-4670-9974-de4e23c2e849",
   "metadata": {},
   "source": [
    "### Dim Causa Siniestro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0454358a-77af-4ea5-9dfe-c62877657b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 1. Selecci√≥n\n",
    "# ===============================\n",
    "dim_causas = df_siniestros.select(\n",
    "    F.col(\"CAUSA FACTOR PRINCIPAL\").alias(\"causa_factor_raw\"),\n",
    "    F.col(\"CAUSA ESPEC√çFICA\").alias(\"causa_especifica_raw\")\n",
    ").dropDuplicates()\n",
    "\n",
    "# ===============================\n",
    "# Helper: funci√≥n para detectar vac√≠os\n",
    "# ===============================\n",
    "def is_null_or_empty(col):\n",
    "    return (F.col(col).isNull()) | (F.trim(F.col(col)) == \"\") | (F.lower(F.col(col)).isin(\n",
    "        \"\", \"no identifica la causa\", \"no cuenta con causa especifica\",\n",
    "        \"en proceso de investigaci√≥n\", \"no aplica\", \"-\", \"null\"\n",
    "    ))\n",
    "\n",
    "# ===============================\n",
    "# 2. Normalizaci√≥n: CAUSA FACTOR PRINCIPAL\n",
    "# ===============================\n",
    "dim_causas = dim_causas.withColumn(\n",
    "    \"causa_factor\",\n",
    "    F.when(is_null_or_empty(\"causa_factor_raw\"), \"No identificado\")\n",
    "     .when(F.lower(\"causa_factor_raw\").like(\"%imprudencia del conductor%\"), \"Conductor ‚Äì Imprudencia\")\n",
    "     .when(F.lower(\"causa_factor_raw\").like(\"%negligencia del conductor%\"), \"Conductor ‚Äì Negligencia\")\n",
    "     .when(F.lower(\"causa_factor_raw\").like(\"%impericia del conductor%\"), \"Conductor ‚Äì Impericia\")\n",
    "     .when(F.lower(\"causa_factor_raw\").like(\"%imprudencia del peat%\"), \"Peat√≥n ‚Äì Imprudencia\")\n",
    "     .when(F.lower(\"causa_factor_raw\").like(\"%pasajero%\"), \"Pasajero ‚Äì Imprudencia\")\n",
    "     .when(F.lower(\"causa_factor_raw\").like(\"%infraestructura%\"), \"Entorno / Infraestructura\")\n",
    "     .when(F.lower(\"causa_factor_raw\").like(\"%investigaci%\"), \"No identificado\")\n",
    "     .otherwise(F.initcap(\"causa_factor_raw\"))\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 3. Normalizaci√≥n: CATEGOR√çA CAUSA (AMPLIADA)\n",
    "# ===============================\n",
    "dim_causas = dim_causas.withColumn(\n",
    "    \"categoria_causa\",\n",
    "    F.when(is_null_or_empty(\"causa_especifica_raw\"), \"No identificado\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%ebriedad%\"), \"Alcohol / Drogas\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%drogadicci√≥n%\"), \"Alcohol / Drogas\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%velocidad%\"), \"Velocidad / Conducci√≥n temeraria\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%sentido contrario%\"), \"Maniobras indebidas\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%girar%\"), \"Maniobras indebidas\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%invas%\"), \"Maniobras indebidas\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%adelant%\"), \"Maniobras indebidas\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%derecho%\"), \"Maniobras indebidas\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%preferente%\"), \"Maniobras indebidas\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%frenar%\"), \"Maniobras indebidas\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%desacato%\"), \"Desacato a se√±alizaci√≥n\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%no encender%\"), \"Desacato a se√±alizaci√≥n\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%dispositiv%\"), \"Distracci√≥n\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%fatiga%\"), \"Distracci√≥n / Estado del conductor\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%cansancio%\"), \"Distracci√≥n / Estado del conductor\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%falla%\"), \"Fallas mec√°nicas\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%neum√°t%\"), \"Fallas mec√°nicas\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%carrocer%\"), \"Fallas mec√°nicas\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%suspensi%\"), \"Fallas mec√°nicas\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%freno%\"), \"Fallas mec√°nicas\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%el√©ctric%\"), \"Fallas mec√°nicas\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%direcci%\"), \"Fallas mec√°nicas\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%pasajero%\"), \"Conducta del pasajero\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%subir%\"), \"Conducta del pasajero\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%bajar%\"), \"Conducta del pasajero\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%cruce%\"), \"Conducta del peat√≥n\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%otro.*peat%\"), \"Conducta del peat√≥n\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%carga%\"), \"Carga / objetos\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%mercanc%\"), \"Carga / objetos\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%objeto%\"), \"Carga / objetos\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%exceso%\"), \"Carga / objetos\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%superficie%\"), \"Entorno / V√≠a\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%se√±alizaci√≥n%\"), \"Entorno / V√≠a\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%estacionado%\"), \"Entorno / V√≠a\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%obras%\"), \"Entorno / V√≠a\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%ambiental%\"), \"Entorno / V√≠a\")\n",
    "     .when(F.lower(\"causa_especifica_raw\").like(\"%abandono%\"), \"Entorno / V√≠a\")\n",
    "     .otherwise(\"Otros\")\n",
    ")\n",
    "\n",
    "# Guardamos causa espec√≠fica limpia\n",
    "dim_causas = dim_causas.withColumn(\n",
    "    \"causa_especifica\",\n",
    "    F.when(is_null_or_empty(\"causa_especifica_raw\"), \"No identificado\")\n",
    "     .otherwise(F.initcap(\"causa_especifica_raw\"))\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 4. ID\n",
    "# ===============================\n",
    "window = Window.orderBy(F.monotonically_increasing_id())\n",
    "dim_causas = dim_causas.withColumn(\"id_causa\", F.row_number().over(window))\n",
    "\n",
    "# ===============================\n",
    "# 5. Selecci√≥n final\n",
    "# ===============================\n",
    "dim_causas = dim_causas.select(\n",
    "    \"id_causa\",\n",
    "    \"causa_factor\",\n",
    "    \"categoria_causa\",\n",
    "    \"causa_especifica\"\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 6. Deduplicar filas \"No identificado\" completas\n",
    "# ===============================\n",
    "dim_causas = dim_causas.dropDuplicates([\"causa_factor\", \"categoria_causa\", \"causa_especifica\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6da9939-a3dc-47dd-a4f5-7937b2c2e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 7. Guardado final\n",
    "# ================================\n",
    "dim_causas.toPandas().to_csv(\n",
    "    \"Dimensiones/dim_causa_siniestro.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b87dea-033c-4889-9c86-cce6fd30eb1b",
   "metadata": {},
   "source": [
    "### Dimension Infraestructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d49ba760-e220-4e80-a4a6-b11c9507482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, upper, trim, regexp_replace, monotonically_increasing_id\n",
    "\n",
    "def normalizar(col_name):\n",
    "    return upper(trim(regexp_replace(col_name, r'\\s+', ' ')))\n",
    "\n",
    "# Selecci√≥n y normalizaci√≥n de columnas\n",
    "df_siniestros = df_siniestros.withColumnRenamed(\"EXISTE CICLOV√çA\", \"EXISTE_CICLOVIA\") \\\n",
    "                             .withColumnRenamed(\"¬øEXISTE SE√ëAL VERTICAL?\", \"EXISTE_SE√ëAL_VERTICAL\") \\\n",
    "                             .withColumnRenamed(\"¬øEXISTE SE√ëAL HORIZONTAL?\", \"EXISTE_SE√ëAL_HORIZONTAL\") \\\n",
    "                             .withColumnRenamed(\"SUPERFICIE DE CALZADA\", \"SUPERFICIE_DE_CALZADA\") \\\n",
    "                             .withColumnRenamed(\"PERFIL LONGITUDINAL V√çA\", \"PERFIL_LONGITUDINAL_VIA\") \\\n",
    "                             .withColumnRenamed(\"CONDICI√ìN CLIM√ÅTICA\", \"CONDICION_CLIMATICA\") \\\n",
    "                             .withColumnRenamed(\"CARACTER√çSTICAS DE V√çA\", \"CARACTERISTICAS_DE_VIA\")\n",
    "\n",
    "# Reemplazar nulos por valores por defecto\n",
    "df_infra = df_siniestros.select(\n",
    "    normalizar(col(\"EXISTE_CICLOVIA\")).alias(\"existe_ciclovia\"),\n",
    "    normalizar(col(\"EXISTE_SE√ëAL_VERTICAL\")).alias(\"senal_vertical\"),\n",
    "    normalizar(col(\"EXISTE_SE√ëAL_HORIZONTAL\")).alias(\"senal_horizontal\"),\n",
    "    normalizar(col(\"SUPERFICIE_DE_CALZADA\")).alias(\"tipo_superficie\"),    \n",
    "    normalizar(col(\"PERFIL_LONGITUDINAL_VIA\")).alias(\"perfil_via\"),\n",
    "    normalizar(col(\"CONDICION_CLIMATICA\")).alias(\"condicion_climatica\"),\n",
    "    normalizar(col(\"CARACTERISTICAS_DE_VIA\")).alias(\"caracteristicas_via\")\n",
    ")\n",
    "\n",
    "# Crear dimensi√≥n con ID √∫nico\n",
    "df_dim_infraestructura = df_infra.dropDuplicates().withColumn(\n",
    "    \"id_infraestructura\", monotonically_increasing_id()\n",
    ")\n",
    "\n",
    "# Reordenar para que id_infraestructura quede primero\n",
    "columnas_ordenadas = [\"id_infraestructura\"] + [c for c in df_dim_infraestructura.columns if c != \"id_infraestructura\"]\n",
    "df_dim_infraestructura = df_dim_infraestructura.select(columnas_ordenadas)\n",
    "\n",
    "# Guardar CSV\n",
    "df_dim_infraestructura.toPandas().to_csv(\"Dimensiones/dim_infraestructura_vial.csv\", header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7093fa88-1296-4247-bb30-f86fe66e06b5",
   "metadata": {},
   "source": [
    "### Hecho Siniestros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc9f0974-13e6-461c-8c3e-e27e732c735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_nombre(col_name):\n",
    "    \"\"\"Normaliza nombres geogr√°ficos: may√∫sculas, sin espacios extra\"\"\"\n",
    "    return upper(trim(regexp_replace(col_name, r'\\s+', ' ')))\n",
    "\n",
    "# Normalizar en tabla de siniestros\n",
    "df_siniestros_norm = df_siniestros.withColumn(\n",
    "    \"depto_norm\", normalizar_nombre(col(\"DEPARTAMENTO\"))\n",
    ").withColumn(\n",
    "    \"prov_norm\", normalizar_nombre(col(\"PROVINCIA\"))\n",
    ").withColumn(\n",
    "    \"dist_norm\", normalizar_nombre(col(\"DISTRITO\"))\n",
    ")\n",
    "\n",
    "# Normalizar en dimensi√≥n ubigeo\n",
    "dim_ubigeo_norm = dim_ubigeo.withColumn(\n",
    "    \"depto_norm\", normalizar_nombre(col(\"departamento\"))\n",
    ").withColumn(\n",
    "    \"prov_norm\", normalizar_nombre(col(\"provincia\"))\n",
    ").withColumn(\n",
    "    \"dist_norm\", normalizar_nombre(col(\"distrito\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cec09efb-1876-4aa8-882f-f5cd4554253a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Dimensi√≥n infraestructura creada con 352 combinaciones √∫nicas\n",
      "\n",
      "============================================================\n",
      "VALIDACI√ìN INICIAL DE DATOS\n",
      "============================================================\n",
      "\n",
      "Total registros en origen: 6,721\n",
      "C√≥digos de siniestro √∫nicos: 6,718\n",
      "‚ö†Ô∏è ADVERTENCIA: Hay 3 duplicados en origen\n",
      "\n",
      "Total fallecidos en origen: 8,001\n",
      "  (Esperado: ~10,000-20,000 para 2021-2023)\n",
      "\n",
      "============================================================\n",
      "PREPARANDO DIMENSI√ìN RED VIAL\n",
      "============================================================\n",
      "\n",
      "Total registros en red vial: 7,340\n",
      "C√≥digos de ruta √∫nicos: 199\n",
      "Tramos por c√≥digo (promedio): 36.88\n",
      "\n",
      "üìä C√≥digos con m√°s tramos (TOP 10):\n",
      "+-------------+-----+\n",
      "|cod_ruta_norm|count|\n",
      "+-------------+-----+\n",
      "|PE-3N        |743  |\n",
      "|PE-5N        |419  |\n",
      "|PE-1S        |323  |\n",
      "|PE-1N        |295  |\n",
      "|PE-08B       |241  |\n",
      "|PE-3S        |237  |\n",
      "|PE-28B       |211  |\n",
      "|PE-20A       |194  |\n",
      "|PE-1NR       |158  |\n",
      "|PE-3SF       |148  |\n",
      "+-------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "‚úì Dimensi√≥n red vial √∫nica creada: 199 registros\n",
      "\n",
      "============================================================\n",
      "CONSTRUYENDO FACT TABLE\n",
      "============================================================\n",
      "\n",
      "1Ô∏è‚É£ Join con dim_tiempo...\n",
      "   Registros: 6,721\n",
      "2Ô∏è‚É£ Join con dim_ubigeo...\n",
      "   Registros: 6,721\n",
      "3Ô∏è‚É£ Join con dim_tipo_siniestro...\n",
      "   Registros: 6,721\n",
      "4Ô∏è‚É£ Join con dim_causas...\n",
      "   Registros: 6,721\n",
      "5Ô∏è‚É£ Join con dim_infraestructura...\n",
      "   Registros: 6,721\n",
      "6Ô∏è‚É£ Join con dim_red_vial (versi√≥n √∫nica)...\n",
      "   Registros ANTES: 6,721\n",
      "   Registros DESPU√âS: 6,721\n",
      "   Diferencia: 0\n",
      "   ‚úÖ No hay duplicaci√≥n\n",
      "\n",
      "============================================================\n",
      "VALIDACI√ìN POST-JOINS\n",
      "============================================================\n",
      "\n",
      "C√≥digos √∫nicos: 6,718\n",
      "Registros totales: 6,721\n",
      "Factor de duplicaci√≥n: 1.00x\n",
      "‚ö†Ô∏è Duplicaci√≥n m√≠nima (<1%) - Aceptable\n",
      "\n",
      "Total fallecidos despu√©s de joins: 8,001\n",
      "Total fallecidos en origen: 8,001\n",
      "Diferencia: 0\n",
      "‚úÖ Fallecidos coinciden - No hay duplicaci√≥n\n",
      "\n",
      "============================================================\n",
      "AN√ÅLISIS DE SINIESTROS SIN RED VIAL\n",
      "============================================================\n",
      "\n",
      "Con red vial: 3,789 (56.38%)\n",
      "Sin red vial: 2,932 (43.62%)\n",
      "\n",
      "üìä Distribuci√≥n sin red vial por TIPO_DE_VIA:\n",
      "+-----------+-----+\n",
      "|TIPO_DE_VIA|count|\n",
      "+-----------+-----+\n",
      "|CARRETERA  |1487 |\n",
      "|AVENIDA    |1038 |\n",
      "|CALLE      |183  |\n",
      "|JIR√ìN      |131  |\n",
      "|OTRO       |68   |\n",
      "|AUTOPISTA  |9    |\n",
      "|PASAJE     |9    |\n",
      "|VIA EXPRESA|6    |\n",
      "|ALAMEDA    |1    |\n",
      "+-----------+-----+\n",
      "\n",
      "\n",
      "============================================================\n",
      "CREANDO FACT TABLE FINAL\n",
      "============================================================\n",
      "\n",
      "‚úì Fact table creada con 6,721 registros\n",
      "\n",
      "============================================================\n",
      "VERIFICACI√ìN FINAL DE FOREIGN KEYS\n",
      "============================================================\n",
      "\n",
      "FK Tiempo nulas: 0\n",
      "FK Ubigeo nulas: 0\n",
      "FK Tipo Siniestro nulas: 0\n",
      "FK Causa Siniestro nulas: 3,458\n",
      "FK Infraestructura nulas: 0\n",
      "FK Red Vial nulas: 2,932\n",
      "\n",
      "‚ö†Ô∏è Hay 3,458 FKs obligatorias nulas\n",
      "\n",
      "üìä Total fallecidos en fact final: 8,001\n",
      "üìä Total fallecidos en origen: 8,001\n",
      "‚úÖ Los fallecidos coinciden perfectamente\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 0. RENOMBRAR COLUMNAS CON ESPACIOS/TILDES\n",
    "# ================================\n",
    "df_siniestros = df_siniestros \\\n",
    "    .withColumnRenamed(\"RED VIAL\", \"RED_VIAL\") \\\n",
    "    .withColumnRenamed(\"C√ìDIGO SINIESTRO\", \"CODIGO_SINIESTRO\") \\\n",
    "    .withColumnRenamed(\"FECHA SINIESTRO\", \"FECHA_SINIESTRO\") \\\n",
    "    .withColumnRenamed(\"HORA SINIESTRO\", \"HORA_SINIESTRO\") \\\n",
    "    .withColumnRenamed(\"CLASE SINIESTRO\", \"CLASE_SINIESTRO\") \\\n",
    "    .withColumnRenamed(\"CANTIDAD DE FALLECIDOS\", \"CANTIDAD_DE_FALLECIDOS\") \\\n",
    "    .withColumnRenamed(\"CANTIDAD DE LESIONADOS\", \"CANTIDAD_DE_LESIONADOS\") \\\n",
    "    .withColumnRenamed(\"CANTIDAD DE VEHICULOS DA√ëADOS\", \"CANTIDAD_DE_VEHICULOS_DANADOS\") \\\n",
    "    .withColumnRenamed(\"TIPO DE V√çA\", \"TIPO_DE_VIA\") \\\n",
    "    .withColumnRenamed(\"CONDICI√ìN CLIM√ÅTICA\", \"CONDICION_CLIMATICA\") \\\n",
    "    .withColumnRenamed(\"CAUSA FACTOR PRINCIPAL\", \"CAUSA_FACTOR_PRINCIPAL\") \\\n",
    "    .withColumnRenamed(\"CAUSA ESPECIFICA\", \"CAUSA_ESPECIFICA\") \\\n",
    "    .withColumnRenamed(\"ZONIFICACI√ìN\", \"ZONIFICACION\") \\\n",
    "    .withColumnRenamed(\"EXISTE CICLOV√çA\", \"EXISTE_CICLOVIA\") \\\n",
    "    .withColumnRenamed(\"¬øEXISTE SE√ëAL VERTICAL?\", \"EXISTE_SE√ëAL_VERTICAL\") \\\n",
    "    .withColumnRenamed(\"¬øEXISTE SE√ëAL HORIZONTAL?\", \"EXISTE_SE√ëAL_HORIZONTAL\") \\\n",
    "    .withColumnRenamed(\"SUPERFICIE DE CALZADA\", \"SUPERFICIE_DE_CALZADA\") \\\n",
    "    .withColumnRenamed(\"PERFIL LONGITUDINAL V√çA\", \"PERFIL_LONGITUDINAL_VIA\") \\\n",
    "    .withColumnRenamed(\"CARACTER√çSTICAS DE V√çA\", \"CARACTERISTICAS_DE_VIA\")\n",
    "\n",
    "# ================================\n",
    "# 0.1 CREAR DIMENSI√ìN INFRAESTRUCTURA\n",
    "# ================================\n",
    "def normalizar(col_name):\n",
    "    \"\"\"Normaliza texto: may√∫sculas, sin espacios extra\"\"\"\n",
    "    return upper(trim(regexp_replace(col_name, r'\\s+', ' ')))\n",
    "\n",
    "df_dim_infraestructura = df_siniestros.select(\n",
    "    normalizar(coalesce(col(\"EXISTE_CICLOVIA\"), lit(\"NO\"))).alias(\"existe_ciclovia\"),\n",
    "    normalizar(coalesce(col(\"EXISTE_SE√ëAL_VERTICAL\"), lit(\"NO\"))).alias(\"senal_vertical\"),\n",
    "    normalizar(coalesce(col(\"EXISTE_SE√ëAL_HORIZONTAL\"), lit(\"NO\"))).alias(\"senal_horizontal\"),\n",
    "    normalizar(coalesce(col(\"SUPERFICIE_DE_CALZADA\"), lit(\"DESCONOCIDO\"))).alias(\"tipo_superficie\"),\n",
    "    normalizar(coalesce(col(\"PERFIL_LONGITUDINAL_VIA\"), lit(\"DESCONOCIDO\"))).alias(\"perfil_via\"),\n",
    "    normalizar(coalesce(col(\"CONDICION_CLIMATICA\"), lit(\"DESCONOCIDO\"))).alias(\"condicion_climatica\"),\n",
    "    normalizar(coalesce(col(\"CARACTERISTICAS_DE_VIA\"), lit(\"DESCONOCIDO\"))).alias(\"caracteristicas_via\")\n",
    ").dropDuplicates()\n",
    "\n",
    "window_infra = Window.orderBy(F.monotonically_increasing_id())\n",
    "df_dim_infraestructura = df_dim_infraestructura.withColumn(\n",
    "    \"id_infraestructura\", \n",
    "    F.row_number().over(window_infra)\n",
    ")\n",
    "\n",
    "columnas_ordenadas = [\"id_infraestructura\"] + [c for c in df_dim_infraestructura.columns if c != \"id_infraestructura\"]\n",
    "df_dim_infraestructura = df_dim_infraestructura.select(columnas_ordenadas)\n",
    "df_dim_infraestructura.toPandas().to_csv(\"Dimensiones/dim_infraestructura_vial.csv\", header=True, index=False)\n",
    "print(f\"\\n‚úì Dimensi√≥n infraestructura creada con {df_dim_infraestructura.count()} combinaciones √∫nicas\")\n",
    "\n",
    "# ================================\n",
    "# 1. CORRECCI√ìN MANUAL PRE-NORMALIZACI√ìN\n",
    "# ================================\n",
    "correcciones_distritos = {\n",
    "    \"VEINTISEIS DE OCTUBRE\": \"VEINTIS√âIS DE OCTUBRE\",\n",
    "    \"ANCO_HUALLO\": \"ANCO-HUALLO\",\n",
    "    \"ANDRES AVELINO CACERES DORREGARAY\": \"ANDR√âS AVELINO C√ÅCERES DORREGARAY\",\n",
    "    \"JOSE MARIA ARGUEDAS\": \"JOS√â MAR√çA ARGUEDAS\",\n",
    "    \"MI PERU\": \"MI PER√ö\",\n",
    "    \"QUISQUI (KICHKI)\": \"QUISQUI\"\n",
    "}\n",
    "\n",
    "mapeo_clase_siniestro = {\n",
    "    \"ATROPELLO FUGA\": \"ATROPELLO (FUGA)\",\n",
    "    \"CHOQUE FUGA\": \"CHOQUE (FUGA)\"\n",
    "}\n",
    "\n",
    "df_siniestros_corr = df_siniestros\n",
    "\n",
    "distrito_col = col(\"DISTRITO\")\n",
    "for sucio, limpio in correcciones_distritos.items():\n",
    "    distrito_col = when(col(\"DISTRITO\") == sucio, lit(limpio)).otherwise(distrito_col)\n",
    "df_siniestros_corr = df_siniestros_corr.withColumn(\"DISTRITO\", distrito_col)\n",
    "\n",
    "clase_col = upper(col(\"CLASE_SINIESTRO\"))\n",
    "for sucio, limpio in mapeo_clase_siniestro.items():\n",
    "    clase_col = when(upper(col(\"CLASE_SINIESTRO\")) == sucio, lit(limpio)).otherwise(clase_col)\n",
    "df_siniestros_corr = df_siniestros_corr.withColumn(\"CLASE_SINIESTRO_NORM\", clase_col)\n",
    "\n",
    "# ================================\n",
    "# 2. NORMALIZACI√ìN GEOGR√ÅFICA\n",
    "# ================================\n",
    "def normalizar_nombre(col_name):\n",
    "    return upper(trim(regexp_replace(col_name, r'\\s+', ' ')))\n",
    "\n",
    "df_siniestros_norm = df_siniestros_corr.withColumn(\n",
    "    \"depto_norm\", normalizar_nombre(col(\"DEPARTAMENTO\"))\n",
    ").withColumn(\n",
    "    \"prov_norm\", normalizar_nombre(col(\"PROVINCIA\"))\n",
    ").withColumn(\n",
    "    \"dist_norm\", normalizar_nombre(col(\"DISTRITO\"))\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 3. NORMALIZAR CAUSAS\n",
    "# ================================\n",
    "def is_null_or_empty(col_name):\n",
    "    return (F.col(col_name).isNull()) | (F.trim(F.col(col_name)) == \"\") | (F.lower(F.col(col_name)).isin(\n",
    "        \"\", \"no identifica la causa\", \"no cuenta con causa especifica\",\n",
    "        \"en proceso de investigaci√≥n\", \"no aplica\", \"-\", \"null\"\n",
    "    ))\n",
    "\n",
    "def normalizar_causa_factor(col_name):\n",
    "    return (\n",
    "        F.when(is_null_or_empty(col_name), \"No identificado\")\n",
    "         .when(F.lower(F.col(col_name)) == \"imprudencia del conductor\", \"Conductor ‚Äì Imprudencia\")\n",
    "         .when(F.lower(F.col(col_name)) == \"negligencia del conductor\", \"Conductor ‚Äì Negligencia\")\n",
    "         .when(F.lower(F.col(col_name)) == \"impericia del conductor\", \"Conductor ‚Äì Impericia\")\n",
    "         .when(F.lower(F.col(col_name)).like(\"%imprudencia del peat%\"), \"Peat√≥n ‚Äì Imprudencia\")\n",
    "         .when(F.lower(F.col(col_name)).like(\"%pasajero%\"), \"Pasajero ‚Äì Imprudencia\")\n",
    "         .when(F.lower(F.col(col_name)).like(\"%infraestructura%\"), \"Entorno / Infraestructura\")\n",
    "         .when(F.lower(F.col(col_name)).like(\"%investigaci%\"), \"No identificado\")\n",
    "         .otherwise(F.initcap(F.col(col_name)))\n",
    "    )\n",
    "\n",
    "df_siniestros_norm = df_siniestros_norm.withColumn(\n",
    "    \"causa_factor_norm\",\n",
    "    normalizar_causa_factor(\"CAUSA_FACTOR_PRINCIPAL\")\n",
    ").withColumn(\n",
    "    \"cod_carretera_norm\", upper(trim(col(\"COD CARRETERA\")))\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 4. NORMALIZAR FECHA Y HORA\n",
    "# ================================\n",
    "df_siniestros_norm = df_siniestros_norm \\\n",
    "    .withColumn(\"fecha_sin\", to_date(col(\"FECHA_SINIESTRO\"), \"dd/MM/yyyy\")) \\\n",
    "    .withColumn(\"hora_raw\", trim(col(\"HORA_SINIESTRO\"))) \\\n",
    "    .withColumn(\"hora_only\",\n",
    "        regexp_extract(col(\"hora_raw\"), \"([0-9]{1,2}:[0-9]{2}(?::[0-9]{2})?)\", 1)\n",
    "    ) \\\n",
    "    .withColumn(\"hora_norm\",\n",
    "        when(col(\"hora_only\") != \"\", col(\"hora_only\")).otherwise(col(\"hora_raw\"))\n",
    "    ) \\\n",
    "    .withColumn(\"hora_norm\",\n",
    "        when(col(\"hora_norm\").rlike(\"^[0-9]{1,2}:[0-9]{2}$\"),\n",
    "             concat(\n",
    "                 lpad(split(col(\"hora_norm\"), \":\").getItem(0), 2, \"0\"),\n",
    "                 lit(\":\"),\n",
    "                 split(col(\"hora_norm\"), \":\").getItem(1),\n",
    "                 lit(\":00\")\n",
    "             )\n",
    "        ).otherwise(col(\"hora_norm\"))\n",
    "    ) \\\n",
    "    .withColumn(\"timestamp_sin\",\n",
    "        to_timestamp(\n",
    "            concat(\n",
    "                date_format(col(\"fecha_sin\"), \"yyyy-MM-dd\"), \n",
    "                lit(\" \"), \n",
    "                col(\"hora_norm\")\n",
    "            ),\n",
    "            \"yyyy-MM-dd HH:mm:ss\"\n",
    "        )\n",
    "    ) \\\n",
    "    .withColumn(\"pk_tiempo_sin\",\n",
    "        when(col(\"timestamp_sin\").isNotNull(),\n",
    "            date_format(col(\"timestamp_sin\"), \"yyyyMMddHHmmss\")\n",
    "        ).otherwise(\n",
    "            concat(\n",
    "                date_format(col(\"fecha_sin\"), \"yyyy\"),\n",
    "                date_format(col(\"fecha_sin\"), \"MM\"),\n",
    "                date_format(col(\"fecha_sin\"), \"dd\"),\n",
    "                lit(\"000000\")\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "# ================================\n",
    "# 5. VALIDACI√ìN INICIAL\n",
    "# ================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDACI√ìN INICIAL DE DATOS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "total_siniestros_origen = df_siniestros_norm.count()\n",
    "siniestros_unicos = df_siniestros_norm.select(\"CODIGO_SINIESTRO\").distinct().count()\n",
    "\n",
    "print(f\"Total registros en origen: {total_siniestros_origen:,}\")\n",
    "print(f\"C√≥digos de siniestro √∫nicos: {siniestros_unicos:,}\")\n",
    "\n",
    "if total_siniestros_origen != siniestros_unicos:\n",
    "    print(f\"‚ö†Ô∏è ADVERTENCIA: Hay {total_siniestros_origen - siniestros_unicos:,} duplicados en origen\")\n",
    "else:\n",
    "    print(\"‚úÖ No hay duplicados en origen\")\n",
    "\n",
    "# Validar fallecidos esperados\n",
    "fallecidos_origen = df_siniestros_norm.agg(F.sum(\"CANTIDAD_DE_FALLECIDOS\")).collect()[0][0]\n",
    "print(f\"\\nTotal fallecidos en origen: {fallecidos_origen:,}\")\n",
    "print(\"  (Esperado: ~10,000-20,000 para 2021-2023)\\n\")\n",
    "\n",
    "# ================================\n",
    "# 6. PREPARAR DIM RED VIAL SIN DUPLICADOS\n",
    "# ================================\n",
    "print(\"=\"*60)\n",
    "print(\"PREPARANDO DIMENSI√ìN RED VIAL\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# An√°lisis de duplicados\n",
    "dim_red_vial_temp = dim_red_vial.withColumn(\n",
    "    \"cod_ruta_norm\", upper(trim(col(\"codigo_ruta\")))\n",
    ")\n",
    "\n",
    "total_red_vial = dim_red_vial_temp.count()\n",
    "codigos_unicos_red = dim_red_vial_temp.select(\"cod_ruta_norm\").distinct().count()\n",
    "\n",
    "print(f\"Total registros en red vial: {total_red_vial:,}\")\n",
    "print(f\"C√≥digos de ruta √∫nicos: {codigos_unicos_red:,}\")\n",
    "print(f\"Tramos por c√≥digo (promedio): {total_red_vial / codigos_unicos_red:.2f}\")\n",
    "\n",
    "# Mostrar c√≥digos con m√°s tramos\n",
    "print(\"\\nüìä C√≥digos con m√°s tramos (TOP 10):\")\n",
    "dim_red_vial_temp.groupBy(\"cod_ruta_norm\") \\\n",
    "    .count() \\\n",
    "    .orderBy(F.desc(\"count\")) \\\n",
    "    .show(10, truncate=False)\n",
    "\n",
    "# Crear versi√≥n √∫nica (tomar el primer registro por c√≥digo)\n",
    "dim_red_vial_unique = dim_red_vial_temp \\\n",
    "    .withColumn(\"row_num\", F.row_number().over(\n",
    "        Window.partitionBy(\"cod_ruta_norm\").orderBy(\"id_red_vial\")\n",
    "    )) \\\n",
    "    .filter(col(\"row_num\") == 1) \\\n",
    "    .drop(\"row_num\")\n",
    "\n",
    "print(f\"\\n‚úì Dimensi√≥n red vial √∫nica creada: {dim_red_vial_unique.count():,} registros\")\n",
    "\n",
    "# ================================\n",
    "# 7. FACT TABLE - JOINS\n",
    "# ================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONSTRUYENDO FACT TABLE\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Join tiempo\n",
    "print(\"1Ô∏è‚É£ Join con dim_tiempo...\")\n",
    "df_siniestros_fact = df_siniestros_norm.alias(\"s\").join(\n",
    "    dim_tiempo.alias(\"t\"),\n",
    "    col(\"s.pk_tiempo_sin\") == col(\"t.pk_tiempo\"),\n",
    "    how=\"left\"\n",
    ")\n",
    "print(f\"   Registros: {df_siniestros_fact.count():,}\")\n",
    "\n",
    "# Join ubigeo\n",
    "print(\"2Ô∏è‚É£ Join con dim_ubigeo...\")\n",
    "df_siniestros_fact = df_siniestros_fact.join(\n",
    "    dim_ubigeo_norm.alias(\"u\"),\n",
    "    (col(\"s.depto_norm\") == col(\"u.depto_norm\")) &\n",
    "    (col(\"s.prov_norm\") == col(\"u.prov_norm\")) &\n",
    "    (col(\"s.dist_norm\") == col(\"u.dist_norm\")),\n",
    "    how=\"left\"\n",
    ")\n",
    "registros_post_ubigeo = df_siniestros_fact.count()\n",
    "print(f\"   Registros: {registros_post_ubigeo:,}\")\n",
    "\n",
    "if registros_post_ubigeo != total_siniestros_origen:\n",
    "    print(f\"   ‚ö†Ô∏è Diferencia: {registros_post_ubigeo - total_siniestros_origen:,}\")\n",
    "\n",
    "# Join tipo siniestro\n",
    "print(\"3Ô∏è‚É£ Join con dim_tipo_siniestro...\")\n",
    "df_siniestros_fact = df_siniestros_fact.join(\n",
    "    dim_tipo_siniestro.alias(\"ts\"),\n",
    "    upper(col(\"s.CLASE_SINIESTRO_NORM\")) == upper(col(\"ts.clase_siniestro\")),\n",
    "    how=\"left\"\n",
    ")\n",
    "print(f\"   Registros: {df_siniestros_fact.count():,}\")\n",
    "\n",
    "# Join causa\n",
    "print(\"4Ô∏è‚É£ Join con dim_causas...\")\n",
    "# Join con ambas columnas para match exacto\n",
    "df_siniestros_fact = df_siniestros_fact.join(\n",
    "    dim_causas.alias(\"c\"),\n",
    "    (col(\"s.causa_factor_norm\") == col(\"c.causa_factor\")) &\n",
    "    (normalizar(col(\"s.CAUSA ESPEC√çFICA\")) == normalizar(col(\"c.causa_especifica\"))),\n",
    "    how=\"left\"\n",
    ")\n",
    "print(f\"   Registros: {df_siniestros_fact.count():,}\")\n",
    "\n",
    "# Join infraestructura\n",
    "print(\"5Ô∏è‚É£ Join con dim_infraestructura...\")\n",
    "df_siniestros_fact = df_siniestros_fact.join(\n",
    "    df_dim_infraestructura.alias(\"i\"),\n",
    "    on=[\n",
    "        normalizar(coalesce(col(\"s.EXISTE_CICLOVIA\"), lit(\"NO\"))) == col(\"i.existe_ciclovia\"),\n",
    "        normalizar(coalesce(col(\"s.EXISTE_SE√ëAL_VERTICAL\"), lit(\"NO\"))) == col(\"i.senal_vertical\"),\n",
    "        normalizar(coalesce(col(\"s.EXISTE_SE√ëAL_HORIZONTAL\"), lit(\"NO\"))) == col(\"i.senal_horizontal\"),\n",
    "        normalizar(coalesce(col(\"s.SUPERFICIE_DE_CALZADA\"), lit(\"DESCONOCIDO\"))) == col(\"i.tipo_superficie\"),\n",
    "        normalizar(coalesce(col(\"s.PERFIL_LONGITUDINAL_VIA\"), lit(\"DESCONOCIDO\"))) == col(\"i.perfil_via\"),\n",
    "        normalizar(coalesce(col(\"s.CONDICION_CLIMATICA\"), lit(\"DESCONOCIDO\"))) == col(\"i.condicion_climatica\"),\n",
    "        normalizar(coalesce(col(\"s.CARACTERISTICAS_DE_VIA\"), lit(\"DESCONOCIDO\"))) == col(\"i.caracteristicas_via\")\n",
    "    ],\n",
    "    how=\"left\"\n",
    ")\n",
    "print(f\"   Registros: {df_siniestros_fact.count():,}\")\n",
    "\n",
    "# Join red vial (SIN DUPLICACI√ìN)\n",
    "print(\"6Ô∏è‚É£ Join con dim_red_vial (versi√≥n √∫nica)...\")\n",
    "registros_antes_red_vial = df_siniestros_fact.count()\n",
    "\n",
    "df_siniestros_fact = df_siniestros_fact.join(\n",
    "    dim_red_vial_unique.select(\"id_red_vial\", \"cod_ruta_norm\"),\n",
    "    col(\"s.cod_carretera_norm\") == col(\"cod_ruta_norm\"),\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "registros_despues_red_vial = df_siniestros_fact.count()\n",
    "print(f\"   Registros ANTES: {registros_antes_red_vial:,}\")\n",
    "print(f\"   Registros DESPU√âS: {registros_despues_red_vial:,}\")\n",
    "print(f\"   Diferencia: {registros_despues_red_vial - registros_antes_red_vial:,}\")\n",
    "\n",
    "if registros_despues_red_vial == registros_antes_red_vial:\n",
    "    print(\"   ‚úÖ No hay duplicaci√≥n\")\n",
    "else:\n",
    "    print(f\"   ‚ùå ERROR: Se duplicaron {registros_despues_red_vial - registros_antes_red_vial:,} registros\")\n",
    "    print(\"   ‚ö†Ô∏è DETENER EJECUCI√ìN - Revisar join de red vial\")\n",
    "\n",
    "# ================================\n",
    "# 8. VALIDACI√ìN POST-JOINS\n",
    "# ================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDACI√ìN POST-JOINS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Validar que no hay duplicaci√≥n\n",
    "codigos_finales = df_siniestros_fact.select(\"s.CODIGO_SINIESTRO\").distinct().count()\n",
    "registros_finales = df_siniestros_fact.count()\n",
    "\n",
    "print(f\"C√≥digos √∫nicos: {codigos_finales:,}\")\n",
    "print(f\"Registros totales: {registros_finales:,}\")\n",
    "print(f\"Factor de duplicaci√≥n: {registros_finales / codigos_finales:.2f}x\")\n",
    "\n",
    "if registros_finales == codigos_finales:\n",
    "    print(\"‚úÖ No hay duplicaci√≥n - 1 registro por siniestro\")\n",
    "elif registros_finales < codigos_finales * 1.01:\n",
    "    print(\"‚ö†Ô∏è Duplicaci√≥n m√≠nima (<1%) - Aceptable\")\n",
    "else:\n",
    "    print(\"‚ùå DUPLICACI√ìN DETECTADA - NO CONTINUAR\")\n",
    "    print(f\"   Se perdieron o duplicaron {abs(registros_finales - codigos_finales):,} registros\")\n",
    "\n",
    "# Validar fallecidos\n",
    "fallecidos_post_join = df_siniestros_fact.agg(F.sum(\"s.CANTIDAD_DE_FALLECIDOS\")).collect()[0][0]\n",
    "print(f\"\\nTotal fallecidos despu√©s de joins: {fallecidos_post_join:,}\")\n",
    "print(f\"Total fallecidos en origen: {fallecidos_origen:,}\")\n",
    "print(f\"Diferencia: {fallecidos_post_join - fallecidos_origen:,}\")\n",
    "\n",
    "if fallecidos_post_join == fallecidos_origen:\n",
    "    print(\"‚úÖ Fallecidos coinciden - No hay duplicaci√≥n\")\n",
    "elif abs(fallecidos_post_join - fallecidos_origen) / fallecidos_origen < 0.01:\n",
    "    print(\"‚úÖ Diferencia m√≠nima (<1%)\")\n",
    "else:\n",
    "    print(\"‚ùå ERROR: Los fallecidos no coinciden - HAY DUPLICACI√ìN\")\n",
    "\n",
    "# ================================\n",
    "# 9. AN√ÅLISIS DE RED VIAL\n",
    "# ================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AN√ÅLISIS DE SINIESTROS SIN RED VIAL\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "sin_red_vial = df_siniestros_fact.filter(col(\"id_red_vial\").isNull()).count()\n",
    "con_red_vial = df_siniestros_fact.filter(col(\"id_red_vial\").isNotNull()).count()\n",
    "\n",
    "print(f\"Con red vial: {con_red_vial:,} ({(con_red_vial/registros_finales)*100:.2f}%)\")\n",
    "print(f\"Sin red vial: {sin_red_vial:,} ({(sin_red_vial/registros_finales)*100:.2f}%)\")\n",
    "\n",
    "if sin_red_vial > 0:\n",
    "    print(\"\\nüìä Distribuci√≥n sin red vial por TIPO_DE_VIA:\")\n",
    "    df_siniestros_fact.filter(col(\"id_red_vial\").isNull()) \\\n",
    "        .groupBy(\"s.TIPO_DE_VIA\") \\\n",
    "        .count() \\\n",
    "        .orderBy(F.desc(\"count\")) \\\n",
    "        .show(10, truncate=False)\n",
    "\n",
    "# ================================\n",
    "# 10. CREAR FACT TABLE FINAL\n",
    "# ================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREANDO FACT TABLE FINAL\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "fact_siniestros = df_siniestros_fact.select(\n",
    "    col(\"s.CODIGO_SINIESTRO\").alias(\"cod_siniestro\"),\n",
    "    col(\"t.pk_tiempo\").alias(\"fk_tiempo\"),\n",
    "    col(\"u.id_ubigeo\").alias(\"fk_ubigeo\"),\n",
    "    col(\"ts.id_tipo_siniestro\").alias(\"fk_tipo_siniestro\"),\n",
    "    col(\"c.id_causa\").alias(\"fk_causa_siniestro\"),\n",
    "    col(\"i.id_infraestructura\").alias(\"fk_infraestructura\"),\n",
    "    col(\"id_red_vial\").cast(\"int\").alias(\"fk_red_vial\"),\n",
    "    col(\"s.CANTIDAD_DE_FALLECIDOS\").cast(\"int\").alias(\"num_fallecidos\"),\n",
    "    col(\"s.CANTIDAD_DE_LESIONADOS\").cast(\"int\").alias(\"num_lesionados\"),\n",
    "    col(\"s.CANTIDAD_DE_VEHICULOS_DANADOS\").cast(\"int\").alias(\"num_vehiculos\"),\n",
    "    col(\"s.ZONA\").alias(\"zona\"),\n",
    "    col(\"s.RED_VIAL\").alias(\"red_vial\"),\n",
    "    col(\"s.CONDICION_CLIMATICA\").alias(\"condicion_climatica\"),\n",
    "    col(\"s.ZONIFICACION\").alias(\"zonificacion\")\n",
    ")\n",
    "\n",
    "# ID autoincremental\n",
    "window = Window.orderBy(F.monotonically_increasing_id())\n",
    "fact_siniestros = fact_siniestros.withColumn(\n",
    "    \"id_fact_siniestro\",\n",
    "    F.row_number().over(window)\n",
    ")\n",
    "\n",
    "print(f\"‚úì Fact table creada con {fact_siniestros.count():,} registros\")\n",
    "\n",
    "# ================================\n",
    "# 11. VERIFICACI√ìN FINAL DE FKs\n",
    "# ================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VERIFICACI√ìN FINAL DE FOREIGN KEYS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "fk_tiempo_null = fact_siniestros.filter(col('fk_tiempo').isNull()).count()\n",
    "fk_ubigeo_null = fact_siniestros.filter(col('fk_ubigeo').isNull()).count()\n",
    "fk_tipo_null = fact_siniestros.filter(col('fk_tipo_siniestro').isNull()).count()\n",
    "fk_causa_null = fact_siniestros.filter(col('fk_causa_siniestro').isNull()).count()\n",
    "fk_infra_null = fact_siniestros.filter(col('fk_infraestructura').isNull()).count()\n",
    "fk_red_null = fact_siniestros.filter(col('fk_red_vial').isNull()).count()\n",
    "\n",
    "print(f\"FK Tiempo nulas: {fk_tiempo_null:,}\")\n",
    "print(f\"FK Ubigeo nulas: {fk_ubigeo_null:,}\")\n",
    "print(f\"FK Tipo Siniestro nulas: {fk_tipo_null:,}\")\n",
    "print(f\"FK Causa Siniestro nulas: {fk_causa_null:,}\")\n",
    "print(f\"FK Infraestructura nulas: {fk_infra_null:,}\")\n",
    "print(f\"FK Red Vial nulas: {fk_red_null:,}\")\n",
    "\n",
    "total_fks_null = fk_tiempo_null + fk_ubigeo_null + fk_tipo_null + fk_causa_null + fk_infra_null\n",
    "\n",
    "if total_fks_null == 0:\n",
    "    print(\"\\n‚úÖ Todas las FKs obligatorias est√°n completas\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Hay {total_fks_null:,} FKs obligatorias nulas\")\n",
    "\n",
    "# Validaci√≥n final de fallecidos\n",
    "fallecidos_final = fact_siniestros.agg(F.sum(\"num_fallecidos\")).collect()[0][0]\n",
    "print(f\"\\nüìä Total fallecidos en fact final: {fallecidos_final:,}\")\n",
    "print(f\"üìä Total fallecidos en origen: {fallecidos_origen:,}\")\n",
    "\n",
    "if fallecidos_final == fallecidos_origen:\n",
    "    print(\"‚úÖ Los fallecidos coinciden perfectamente\")\n",
    "elif abs(fallecidos_final - fallecidos_origen) < 100:\n",
    "    print(\"‚úÖ Diferencia m√≠nima aceptable\")\n",
    "else:\n",
    "    print(\"‚ùå ERROR: Diferencia significativa en fallecidos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fc9ad8",
   "metadata": {},
   "source": [
    "<table width=\"99%\">\n",
    "  <tr>\n",
    "    <td bgcolor=\"#FFBA39\">\n",
    "      <h2 style=\"color: #000000; text-align: left;\">Explorando Resultado</h2>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ac4f713-e720-407e-b55d-576d9b864815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GUARDANDO FACT TABLE\n",
      "============================================================\n",
      "\n",
      "Schema final:\n",
      "root\n",
      " |-- cod_siniestro: string (nullable = true)\n",
      " |-- fk_tiempo: string (nullable = true)\n",
      " |-- fk_ubigeo: integer (nullable = true)\n",
      " |-- fk_tipo_siniestro: integer (nullable = true)\n",
      " |-- fk_causa_siniestro: integer (nullable = true)\n",
      " |-- fk_infraestructura: integer (nullable = true)\n",
      " |-- fk_red_vial: integer (nullable = true)\n",
      " |-- num_fallecidos: integer (nullable = true)\n",
      " |-- num_lesionados: integer (nullable = true)\n",
      " |-- num_vehiculos: integer (nullable = true)\n",
      " |-- zona: string (nullable = true)\n",
      " |-- red_vial: string (nullable = true)\n",
      " |-- condicion_climatica: string (nullable = true)\n",
      " |-- zonificacion: string (nullable = true)\n",
      " |-- id_fact_siniestro: integer (nullable = false)\n",
      "\n",
      "\n",
      "Primeras 3 filas:\n",
      "-RECORD 0-----------------------------\n",
      " cod_siniestro       | A-2021-01-22   \n",
      " fk_tiempo           | 20210101174500 \n",
      " fk_ubigeo           | 1789           \n",
      " fk_tipo_siniestro   | 10             \n",
      " fk_causa_siniestro  | 1              \n",
      " fk_infraestructura  | 136            \n",
      " fk_red_vial         | NULL           \n",
      " num_fallecidos      | 1              \n",
      " num_lesionados      | 1              \n",
      " num_vehiculos       | 2              \n",
      " zona                | URBANA         \n",
      " red_vial            | URBANO         \n",
      " condicion_climatica | LLUVIOSO       \n",
      " zonificacion        | COMERCIAL      \n",
      " id_fact_siniestro   | 1              \n",
      "-RECORD 1-----------------------------\n",
      " cod_siniestro       | A-2022-01-296  \n",
      " fk_tiempo           | 20220101185700 \n",
      " fk_ubigeo           | 1048           \n",
      " fk_tipo_siniestro   | 7              \n",
      " fk_causa_siniestro  | 36             \n",
      " fk_infraestructura  | 99             \n",
      " fk_red_vial         | 19             \n",
      " num_fallecidos      | 1              \n",
      " num_lesionados      | 2              \n",
      " num_vehiculos       | 1              \n",
      " zona                | RURAL          \n",
      " red_vial            | NACIONAL       \n",
      " condicion_climatica | DESPEJADO      \n",
      " zonificacion        | RURAL          \n",
      " id_fact_siniestro   | 2              \n",
      "-RECORD 2-----------------------------\n",
      " cod_siniestro       | A-2023-01-12   \n",
      " fk_tiempo           | 20230101040000 \n",
      " fk_ubigeo           | 164            \n",
      " fk_tipo_siniestro   | 9              \n",
      " fk_causa_siniestro  | NULL           \n",
      " fk_infraestructura  | 51             \n",
      " fk_red_vial         | 48             \n",
      " num_fallecidos      | 1              \n",
      " num_lesionados      | 7              \n",
      " num_vehiculos       | 1              \n",
      " zona                | RURAL          \n",
      " red_vial            | NACIONAL       \n",
      " condicion_climatica | DESPEJADO      \n",
      " zonificacion        | RURAL          \n",
      " id_fact_siniestro   | 3              \n",
      "only showing top 3 rows\n",
      "\n",
      "\n",
      "üìä ESTAD√çSTICAS FINALES:\n",
      "Total registros: 6,721\n",
      "Total fallecidos: 8,001\n",
      "Total lesionados: 5,601\n",
      "Total veh√≠culos: 6,220\n",
      "\n",
      "üíæ Guardando como CSV...\n",
      "‚úì CSV guardado en: Fact/fact_siniestros_spark/\n",
      "  Renombra el archivo part-*.csv a 'fact_siniestros.csv'\n",
      "\n",
      "üíæ Guardando como Parquet...\n",
      "‚úì Parquet guardado en: Fact/fact_siniestros.parquet\n",
      "\n",
      "============================================================\n",
      "‚úÖ PROCESO COMPLETADO EXITOSAMENTE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ================================\n",
    "# 12. GUARDADO OPTIMIZADO\n",
    "# ================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GUARDANDO FACT TABLE\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Verificar schema antes de guardar\n",
    "print(\"Schema final:\")\n",
    "fact_siniestros.printSchema()\n",
    "\n",
    "print(\"\\nPrimeras 3 filas:\")\n",
    "fact_siniestros.show(3, truncate=False, vertical=True)\n",
    "\n",
    "# Estad√≠sticas finales\n",
    "print(\"\\nüìä ESTAD√çSTICAS FINALES:\")\n",
    "print(f\"Total registros: {fact_siniestros.count():,}\")\n",
    "print(f\"Total fallecidos: {fallecidos_final:,}\")\n",
    "print(f\"Total lesionados: {fact_siniestros.agg(F.sum('num_lesionados')).collect()[0][0]:,}\")\n",
    "print(f\"Total veh√≠culos: {fact_siniestros.agg(F.sum('num_vehiculos')).collect()[0][0]:,}\")\n",
    "\n",
    "# Guardar como CSV con Spark\n",
    "print(\"\\nüíæ Guardando como CSV...\")\n",
    "fact_siniestros.coalesce(1) \\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"encoding\", \"UTF-8\") \\\n",
    "    .csv(\"Fact/fact_siniestros_spark\")\n",
    "\n",
    "print(\"‚úì CSV guardado en: Fact/fact_siniestros_spark/\")\n",
    "print(\"  Renombra el archivo part-*.csv a 'fact_siniestros.csv'\")\n",
    "\n",
    "# Guardar como Parquet\n",
    "print(\"\\nüíæ Guardando como Parquet...\")\n",
    "fact_siniestros.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(\"Fact/fact_siniestros.parquet\")\n",
    "\n",
    "print(\"‚úì Parquet guardado en: Fact/fact_siniestros.parquet\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ PROCESO COMPLETADO EXITOSAMENTE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfef353e-3ec0-440a-af90-72651b3d4a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DIAGN√ìSTICO DE DUPLICACI√ìN DE REGISTROS\n",
      "============================================================\n",
      "\n",
      "üìä ANTES del join con Red Vial:\n",
      "Total registros: 6,721\n",
      "\n",
      "üîç Verificando duplicados en dim_red_vial:\n",
      "\n",
      "C√≥digos de ruta duplicados en dim_red_vial:\n",
      "+-------------+-----+\n",
      "|cod_ruta_norm|count|\n",
      "+-------------+-----+\n",
      "|PE-3N        |743  |\n",
      "|PE-5N        |419  |\n",
      "|PE-1S        |323  |\n",
      "|PE-1N        |295  |\n",
      "|PE-08B       |241  |\n",
      "|PE-3S        |237  |\n",
      "|PE-28B       |211  |\n",
      "|PE-20A       |194  |\n",
      "|PE-1NR       |158  |\n",
      "|PE-3SF       |148  |\n",
      "|PE-14A       |141  |\n",
      "|PE-18        |138  |\n",
      "|PE-30C       |114  |\n",
      "|PE-3ND       |103  |\n",
      "|PE-34H       |92   |\n",
      "|PE-5NA       |90   |\n",
      "|PE-24        |88   |\n",
      "|PE-3SG       |87   |\n",
      "|PE-34B       |82   |\n",
      "|PE-40        |77   |\n",
      "+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "üìã Ejemplo de registros duplicados para un c√≥digo:\n",
      "\n",
      "C√≥digo duplicado: PE-3SB\n",
      "+-----------+------------+-----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+---------+--------+-----------+------------+-------------+------------+-------------+------------+--------------+----------------+------------+-------------+------+----------+----------+--------------+---------+------------------+---+---------+-------------+\n",
      "|id_red_vial|cod_red_vial|codigo_ruta|nombre_ruta                                                                                                                                                                                |id_tramo|km_inicio|km_final|longitud_km|nro_carriles|ancho_calzada|tipo_red    |clasificacion|es_autopista|sentido       |cod_departamento|departamento|cod_provincia|region|topografia|estado_via|superficie_km2|logistico|operacion         |imd|peajes   |cod_ruta_norm|\n",
      "+-----------+------------+-----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+---------+--------+-----------+------------+-------------+------------+-------------+------------+--------------+----------------+------------+-------------+------+----------+----------+--------------+---------+------------------+---+---------+-------------+\n",
      "|9          |1223        |PE-3SB     |Emp. PE-3S (Dv. Pte. Stuart) - Muqui - Huancani - Sincos - Mito - Orcotuna - Sicaya - Pilcomayo (PE-24) - Huamancaca Chico - Tres de Diciembre - Chupuro - Viques - Emp. PE-3S (Huayucachi)|1       |35.08    |39.355  |4.275      |2           |10.4         |Red Nacional|Otro         |No          |Unidireccional|12              |JUNIN       |1201         |SIERRA|Otro      |Otro      |1.0           |220.0    |RM¬†499-2009-MTC/02|0.0|Concesi√≥n|PE-3SB       |\n",
      "|932        |4784        |PE-3SB     |Emp. PE-3S (Dv. Pte. Stuart) - Muqui - Huancani - Sincos - Mito - Orcotuna - Sicaya - Pilcomayo (PE-24) - Huamancaca Chico - Tres de Diciembre - Chupuro - Viques - Emp. PE-3S (Huayucachi)|1       |30.096   |35.08   |4.984      |2           |10.4         |Red Nacional|Otro         |No          |Unidireccional|12              |JUNIN       |1201         |SIERRA|Otro      |Otro      |1.0           |220.0    |RM¬†499-2009-MTC/02|0.0|Concesi√≥n|PE-3SB       |\n",
      "|2401       |9701        |PE-3SB     |Emp. PE-3S (Dv. Pte. Stuart) - Muqui - Huancani - Sincos - Mito - Orcotuna - Sicaya - Pilcomayo (PE-24) - Huamancaca Chico - Tres de Diciembre - Chupuro - Viques - Emp. PE-3S (Huayucachi)|2       |39.355   |39.376  |0.021      |2           |10.4         |Red Nacional|Otro         |No          |Unidireccional|12              |JUNIN       |1201         |SIERRA|Otro      |Otro      |0.0           |220.0    |RM¬†499-2009-MTC/02|0.0|Peaje    |PE-3SB       |\n",
      "|2561       |722         |PE-3SB     |Emp. PE-3S (Dv. Pte. Stuart) - Muqui - Huancani - Sincos - Mito - Orcotuna - Sicaya - Pilcomayo (PE-24) - Huamancaca Chico - Tres de Diciembre - Chupuro - Viques - Emp. PE-3S (Huayucachi)|1       |0.048    |0.465   |0.417      |2           |10.4         |Red Nacional|Otro         |No          |Unidireccional|12              |JUNIN       |1204         |SIERRA|Otro      |Otro      |1.0           |220.0    |RM¬†499-2009-MTC/02|0.0|Concesi√≥n|PE-3SB       |\n",
      "|2785       |2125        |PE-3SB     |Emp. PE-3S (Dv. Pte. Stuart) - Muqui - Huancani - Sincos - Mito - Orcotuna - Sicaya - Pilcomayo (PE-24) - Huamancaca Chico - Tres de Diciembre - Chupuro - Viques - Emp. PE-3S (Huayucachi)|1       |0.465    |18.214  |17.749     |2           |10.4         |Red Nacional|Otro         |No          |Unidireccional|12              |JUNIN       |1204         |SIERRA|Otro      |Otro      |1.0           |220.0    |RM¬†499-2009-MTC/02|0.0|Concesi√≥n|PE-3SB       |\n",
      "|5290       |4783        |PE-3SB     |Emp. PE-3S (Dv. Pte. Stuart) - Muqui - Huancani - Sincos - Mito - Orcotuna - Sicaya - Pilcomayo (PE-24) - Huamancaca Chico - Tres de Diciembre - Chupuro - Viques - Emp. PE-3S (Huayucachi)|1       |18.214   |30.096  |11.882     |2           |10.4         |Red Nacional|Otro         |No          |Unidireccional|12              |JUNIN       |1202         |SIERRA|Otro      |Otro      |1.0           |220.0    |RM¬†499-2009-MTC/02|0.0|Concesi√≥n|PE-3SB       |\n",
      "|5847       |844         |PE-3SB     |Emp. PE-3S (Dv. Pte. Stuart) - Muqui - Huancani - Sincos - Mito - Orcotuna - Sicaya - Pilcomayo (PE-24) - Huamancaca Chico - Tres de Diciembre - Chupuro - Viques - Emp. PE-3S (Huayucachi)|1       |0.0      |0.048   |0.048      |2           |10.4         |Red Nacional|Otro         |No          |Unidireccional|12              |JUNIN       |1204         |SIERRA|Otro      |Otro      |1.0           |220.0    |RM¬†499-2009-MTC/02|0.0|Concesi√≥n|PE-3SB       |\n",
      "+-----------+------------+-----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+---------+--------+-----------+------------+-------------+------------+-------------+------------+--------------+----------------+------------+-------------+------+----------+----------+--------------+---------+------------------+---+---------+-------------+\n",
      "\n",
      "\n",
      "üìä Estad√≠sticas de dim_red_vial:\n",
      "Total registros: 7,340\n",
      "C√≥digos √∫nicos: 199\n",
      "Registros duplicados: 7,141\n",
      "\n",
      "üìç TOP 20 c√≥digos de carretera en siniestros:\n",
      "+------------------+-----+\n",
      "|cod_carretera_norm|count|\n",
      "+------------------+-----+\n",
      "|NO CORRESPONDE    |1445 |\n",
      "|PE-1N             |821  |\n",
      "|PE-3S             |460  |\n",
      "|PE-1S             |448  |\n",
      "|SIN CLASIFICAR    |242  |\n",
      "|PE-3N             |215  |\n",
      "|PE-5N             |173  |\n",
      "|PE-34A            |136  |\n",
      "|PE-1NJ            |104  |\n",
      "|PE-22             |89   |\n",
      "|PE-28B            |60   |\n",
      "|PE-30C            |57   |\n",
      "|PE-28A            |53   |\n",
      "|PE-34H            |51   |\n",
      "|PE-20             |50   |\n",
      "|PE-10A            |48   |\n",
      "|PE-34B            |46   |\n",
      "|PE-1SD            |42   |\n",
      "|PE-08             |37   |\n",
      "|PE-5S             |36   |\n",
      "+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# DIAGN√ìSTICO: ¬øPOR QU√â AUMENTARON LAS FILAS?\n",
    "# ================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DIAGN√ìSTICO DE DUPLICACI√ìN DE REGISTROS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# 1. Contar registros ANTES del join con red vial\n",
    "print(\"üìä ANTES del join con Red Vial:\")\n",
    "registros_antes = df_siniestros_fact.count()\n",
    "print(f\"Total registros: {registros_antes:,}\\n\")\n",
    "\n",
    "# 2. Verificar duplicados en dim_red_vial\n",
    "print(\"üîç Verificando duplicados en dim_red_vial:\")\n",
    "print(\"\\nC√≥digos de ruta duplicados en dim_red_vial:\")\n",
    "dim_red_vial.withColumn(\"cod_ruta_norm\", upper(trim(col(\"codigo_ruta\")))) \\\n",
    "    .groupBy(\"cod_ruta_norm\") \\\n",
    "    .count() \\\n",
    "    .filter(col(\"count\") > 1) \\\n",
    "    .orderBy(F.desc(\"count\")) \\\n",
    "    .show(20, truncate=False)\n",
    "\n",
    "# 3. Ver ejemplos de c√≥digos duplicados\n",
    "print(\"\\nüìã Ejemplo de registros duplicados para un c√≥digo:\")\n",
    "ejemplo_codigo = dim_red_vial \\\n",
    "    .withColumn(\"cod_ruta_norm\", upper(trim(col(\"codigo_ruta\")))) \\\n",
    "    .groupBy(\"cod_ruta_norm\") \\\n",
    "    .count() \\\n",
    "    .filter(col(\"count\") > 1) \\\n",
    "    .first()\n",
    "\n",
    "if ejemplo_codigo:\n",
    "    codigo_dup = ejemplo_codigo[\"cod_ruta_norm\"]\n",
    "    print(f\"\\nC√≥digo duplicado: {codigo_dup}\")\n",
    "    dim_red_vial.withColumn(\"cod_ruta_norm\", upper(trim(col(\"codigo_ruta\")))) \\\n",
    "        .filter(col(\"cod_ruta_norm\") == codigo_dup) \\\n",
    "        .show(truncate=False)\n",
    "\n",
    "# 4. Cu√°ntos c√≥digos √∫nicos vs total de registros\n",
    "total_red_vial = dim_red_vial.count()\n",
    "codigos_unicos = dim_red_vial.select(\"codigo_ruta\").distinct().count()\n",
    "print(f\"\\nüìä Estad√≠sticas de dim_red_vial:\")\n",
    "print(f\"Total registros: {total_red_vial:,}\")\n",
    "print(f\"C√≥digos √∫nicos: {codigos_unicos:,}\")\n",
    "print(f\"Registros duplicados: {total_red_vial - codigos_unicos:,}\")\n",
    "\n",
    "# 5. Ver distribuci√≥n de siniestros por c√≥digo de carretera\n",
    "print(\"\\nüìç TOP 20 c√≥digos de carretera en siniestros:\")\n",
    "df_siniestros_norm.groupBy(\"cod_carretera_norm\") \\\n",
    "    .count() \\\n",
    "    .orderBy(F.desc(\"count\")) \\\n",
    "    .show(20, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
